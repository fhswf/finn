{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62cca338-f4ef-46ef-a820-78ca4b534390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './citrinet-finn-hw.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3435def5b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"./citrinet-finn-hw.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe474a1-5a1c-46b6-9b03-2f22a49ea6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_279_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_281_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_284_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_286_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_288_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_290_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_295_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_298_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_301_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_303_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_305_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_307_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_312_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_315_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_318_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_320_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_322_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_324_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_329_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_332_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_335_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_337_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_339_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_341_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_346_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_349_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_352_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_354_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_356_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_358_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_363_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_366_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_371_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_373_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_376_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_378_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_380_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_382_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_387_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_390_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_393_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_395_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_397_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_399_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_404_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_407_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_410_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_412_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_414_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_416_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_421_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_424_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_427_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_429_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_431_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_433_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_438_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_441_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_444_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_446_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_448_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_450_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_455_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_458_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_461_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_463_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_465_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_467_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_472_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_475_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_478_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_480_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_482_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_484_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_489_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_492_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_495_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_497_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_499_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_501_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_506_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_509_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_512_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_514_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_516_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_518_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_523_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_526_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_529_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_531_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_533_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_535_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_540_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_543_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_546_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_548_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_550_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_552_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_557_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_560_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_563_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_565_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_567_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_569_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_574_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_577_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_580_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_582_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_584_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_586_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_591_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_594_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_597_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_599_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_601_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_603_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_608_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_611_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_614_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_616_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_618_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_620_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_625_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_628_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_633_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/src/finn/transformation/qonnx/qonnx_activation_handlers.py:412: UserWarning: No layout annotations for Quant_635_out0: Assuming channel dimension at index 1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "model = ModelWrapper(\"./citrinet.onnx\")\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(\"./citrinet-finn.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730d378a-200f-41f1-89f4-a7f77ea5813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "\n",
    "model = ModelWrapper(\"./citrinet-finn.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(\"./citrinet-finn-tidy-up.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a30a5c9-8008-4c52-b99c-f32edb5852f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npawolka/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:382: UserWarning: find_consumer: found multiple consumers, returning first one\n",
      "  warnings.warn(\"find_consumer: found multiple consumers, returning first one\")\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "\n",
    "model = ModelWrapper(\"./citrinet-finn-tidy-up.onnx\")\n",
    "model = model.transform(absorb.AbsorbSignBiasIntoMultiThreshold())\n",
    "model = model.transform(Streamline())\n",
    "model.save(\"./citrinet-finn-streamlined-pre_lower.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "940f5e72-e746-4c2f-90d9-b94fcee19ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "from finn.transformation.streamline.transpose import CollapseRepeatedTranspose\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from finn.transformation.streamline.collapse_repeated import CollapseRepeatedMul\n",
    "\n",
    "\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "model = ModelWrapper(\"./citrinet-finn-streamlined-pre_lower.onnx\")\n",
    "\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model = model.transform(reorder.MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(reorder.MoveAddPastFork())\n",
    "model = model.transform(reorder.MoveMulPastFork())\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(reorder.MoveTransposePastMul())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(to_hw.InferGlobalAccPoolLayer())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastAdd())\n",
    "model = model.transform(reorder.MoveTransposePastMul())\n",
    "model = model.transform(CollapseRepeatedTranspose())\n",
    "model = model.transform(reorder.MoveAddPastMul())\n",
    "model = model.transform(CollapseRepeatedMul())\n",
    "\n",
    "#model = model.transform(reorder.MoveMultiThresholdPastTranspose())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "model = model.transform(reorder.MoveMultiThresholdBeforeFork())\n",
    "model = model.transform(reorder.MoveMatMulPastFork())\n",
    "\n",
    "model.save(\"./test-lower.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae493e3-9c3d-4d32-8d93-b565f644d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from convert_to_hw import InferQuantizedMatrixVectorActivation\n",
    "\n",
    "model = ModelWrapper(\"./test-lower.onnx\")\n",
    "\n",
    "model = model.transform(to_hw.InferElementwiseBinaryOperation())\n",
    "#model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "model = model.transform(to_hw.InferVectorVectorActivation())\n",
    "# needed for non-bipolar MatMul layers\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "model.save(\"./citrinet-vector.onnx\")\n",
    "\n",
    "# TopK to LabelSelect\n",
    "#model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "# input quantization (if any) as standalone threshold\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "# needed for convolutions -- TODO always exec?\n",
    "need_conv = len(model.get_nodes_by_op_type(\"Im2Col\")) > 0\n",
    "if need_conv:\n",
    "    model = model.transform(to_hw.InferConvInpGen())\n",
    "    #model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "    #model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "#model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "#model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model = model.transform(to_hw.InferDuplicateStreamsLayer())\n",
    "\n",
    "model.save(\"./citrinet-finn-hw.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ae57d-ec55-4d70-a56d-9cfe42026ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "from finn.transformation.streamline.transpose import CollapseRepeatedTranspose\n",
    "\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "model = ModelWrapper(\"./citrinet-finn-hw.onnx\")\n",
    "\n",
    "model = model.transform(to_hw.InferDuplicateStreamsLayer())\n",
    "\n",
    "model.save(\"./test.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4895cdc7-3ace-4023-8d62-f6e2017d0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "import torch\n",
    "\n",
    "model = ModelWrapper(\"./citrinet.onnx\")\n",
    "input_tensor = torch.randn((1, 80, 8192))\n",
    "input_dict = {\"global_in\": input_tensor.cpu().numpy() }\n",
    "output_dict = oxe.execute_onnx(model, input_dict)\n",
    "produced_qonnx = output_dict[list(output_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f56872fd-d542-4f97-b41f-77c95fb32d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 8192, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44298fe9-72cb-4843-8758-b9acc2b9a3d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor eK0ofg can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor hcDTUe can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor cR2huG can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor 2lqx10 can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor BmNHX6 can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor BEXPoZ can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor qZlWNF can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor NXjL6F can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor NXIJRu can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor CQGUjL can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor 5y65lD can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor D2K6SK can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor fXLOT7 can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor p6e71c can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor UfEu8v can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor K61ZCY can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor zsNNtF can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor AkMzVZ can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor rpE9NA can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n",
      "/home/npawolka/finn/deps/qonnx/src/qonnx/util/basic.py:296: UserWarning: The values of tensor ZZ7kDl can't be represented with the set datatype annotation (INT8), they will be rounded to match the datatype annotation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(\"./citrinet-finn-hw.onnx\")\n",
    "input_dict = {\"global_in\": input_tensor.cpu().numpy() }\n",
    "output_dict = oxe.execute_onnx(model, input_dict)\n",
    "produced_finn = output_dict[list(output_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9d1c500-ce30-4b87-b32a-0b8e8ef289d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch.from_numpy(produced_qonnx).squeeze(), torch.from_numpy(produced_finn).squeeze(), rtol=0.01, atol=100 * 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30b7f04b-7e4e-4b93-885d-374e1db2c8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.5490794, -5.549089 , -5.5490694, ..., -5.5490756,\n",
       "         -5.5490785, -5.5490785],\n",
       "        [-5.5490794, -5.549089 , -5.5490694, ..., -5.5490756,\n",
       "         -5.5490785, -5.5490785],\n",
       "        [-5.5490794, -5.549089 , -5.5490694, ..., -5.5490756,\n",
       "         -5.5490785, -5.5490785],\n",
       "        ...,\n",
       "        [-5.5490794, -5.549089 , -5.5490694, ..., -5.5490756,\n",
       "         -5.5490785, -5.5490785],\n",
       "        [-5.5490794, -5.549089 , -5.5490694, ..., -5.5490756,\n",
       "         -5.5490785, -5.5490785],\n",
       "        [-5.5490794, -5.549089 , -5.5490694, ..., -5.5490756,\n",
       "         -5.5490785, -5.5490785]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produced_finn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
